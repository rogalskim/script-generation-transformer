:construction: Work in progress :construction:

# script-generation-transformer
Re-implementation of the Udacity Generate Tv Scripts project, this time using the transformer architecture.

### Contents
* [tv_script_transformer.ipynb](tv_script_transformer.ipynb) - my transformer implementaion of the TV script generator.
* [dlnd_tv_script_generation.ipynb](dlnd_tv_script_generation.ipynb) - original Udacity project notebook, containing my LSTM-based solution, for comparison.
* [helper.py](helper.py) - small Python module provided by Udacity for loading and saving project checkpoints.
* [problem_unittests.py](problem_unittests.py) - another script file authored by Udacity; contains tests for the original project notebook.


### Resources
* [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)
* [PyTorch Transformer tutorial](https://pytorch.org/tutorials/beginner/transformer_tutorial.html)
* [The Illustrated Transformer - Jay Alammar](http://jalammar.github.io/illustrated-transformer/)
* [The Annotated Tranformer - Harvard NLP](http://nlp.seas.harvard.edu/2018/04/03/attention.html)
* [Huggingface transformers repo](https://github.com/huggingface/transformers)
