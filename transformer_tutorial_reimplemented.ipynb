{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Sequence-to-Sequence Modeling with nn.Transformer and TorchText\n",
    "===============================================================\n",
    "\n",
    "This is a tutorial on how to train a sequence-to-sequence model\n",
    "that uses the\n",
    "`nn.Transformer <https://pytorch.org/docs/master/nn.html?highlight=nn%20transformer#torch.nn.Transformer>`__ module.\n",
    "\n",
    "PyTorch 1.2 release includes a standard transformer module based on the\n",
    "paper `Attention is All You\n",
    "Need <https://arxiv.org/pdf/1706.03762.pdf>`__. The transformer model\n",
    "has been proved to be superior in quality for many sequence-to-sequence\n",
    "problems while being more parallelizable. The ``nn.Transformer`` module\n",
    "relies entirely on an attention mechanism (another module recently\n",
    "implemented as `nn.MultiheadAttention <https://pytorch.org/docs/master/nn.html?highlight=multiheadattention#torch.nn.MultiheadAttention>`__) to draw global dependencies\n",
    "between input and output. The ``nn.Transformer`` module is now highly\n",
    "modularized such that a single component (like `nn.TransformerEncoder <https://pytorch.org/docs/master/nn.html?highlight=nn%20transformerencoder#torch.nn.TransformerEncoder>`__\n",
    "in this tutorial) can be easily adapted/composed.\n",
    "\n",
    "![](../_static/img/transformer_architecture.jpg)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model\n",
    "----------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we train ``nn.TransformerEncoder`` model on a\n",
    "language modeling task. The language modeling task is to assign a\n",
    "probability for the likelihood of a given word (or a sequence of words)\n",
    "to follow a sequence of words. A sequence of tokens are passed to the embedding\n",
    "layer first, followed by a positional encoding layer to account for the order\n",
    "of the word (see the next paragraph for more details). The\n",
    "``nn.TransformerEncoder`` consists of multiple layers of\n",
    "`nn.TransformerEncoderLayer <https://pytorch.org/docs/master/nn.html?highlight=transformerencoderlayer#torch.nn.TransformerEncoderLayer>`__. Along with the input sequence, a square\n",
    "attention mask is required because the self-attention layers in\n",
    "``nn.TransformerEncoder`` are only allowed to attend the earlier positions in\n",
    "the sequence. For the language modeling task, any tokens on the future\n",
    "positions should be masked. To have the actual words, the output\n",
    "of ``nn.TransformerEncoder`` model is sent to the final Linear\n",
    "layer, which is followed by a log-Softmax function.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``PositionalEncoding`` module injects some information about the\n",
    "relative or absolute position of the tokens in the sequence. The\n",
    "positional encodings have the same dimension as the embeddings so that\n",
    "the two can be summed. Here, we use ``sine`` and ``cosine`` functions of\n",
    "different frequencies.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchtext\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, dimension: int, dropout: int=0.1, max_length: int=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        positional_values = self.__generate_position_values(dimension, max_length)\n",
    "        self.register_buffer(\"positional_values\", positional_values)\n",
    "        \n",
    "    @staticmethod\n",
    "    def __generate_position_values(dimension: int, max_length: int):\n",
    "        values = torch.zeros(max_length, dimension)\n",
    "        positions = torch.arange(0, max_length, dtype=torch.float)\n",
    "        positions = positions.unsqueeze(1)\n",
    "        \n",
    "        scaling_steps = torch.arange(0, dimension, 2).float()\n",
    "        scaling = torch.exp(scaling_steps * (-math.log(10000.0)/dimension))\n",
    "        \n",
    "        values[:, 0::2] = torch.sin(positions * scaling)\n",
    "        values[:, 1::2] = torch.cos(positions * scaling)\n",
    "        values = values.unsqueeze(0).transpose(0, 1)\n",
    "        \n",
    "        return values\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + self.positional_values[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerScriptGenerator(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocabulary_size: int,\n",
    "                 embedding_dim: int,\n",
    "                 attention_head_count: int,\n",
    "                 encoder_fc_dim: int,\n",
    "                 encoder_layer_count: int,\n",
    "                 dropout: float=0.5) -> None:\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_mask = None\n",
    "        self.embedding = nn.Embedding(vocabulary_size, embedding_dim)\n",
    "        self.embedding_scale = math.sqrt(embedding_dim)\n",
    "        self.positional_encoder = PositionalEncoding(embedding_dim, dropout)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(embedding_dim, attention_head_count, encoder_fc_dim, dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, encoder_layer_count)\n",
    "        self.decoder = nn.Linear(embedding_dim, vocabulary_size)\n",
    "        \n",
    "        self.__init_weights()\n",
    "        \n",
    "    def __init_weights(self) -> None:\n",
    "        value_range = 0.1\n",
    "        self.embedding.weight.data.uniform_(-value_range, value_range)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-value_range, value_range)\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def __generate_input_mask(mask_size: int) -> torch.Tensor():\n",
    "        mask = torch.ones(mask_size, mask_size, dtype=bool)\n",
    "        mask = torch.triu(mask).t().float()\n",
    "        mask = mask.masked_fill(mask == 0, float('-inf'))\n",
    "        mask = mask.masked_fill(mask == 1, 0.0)\n",
    "        return mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def __get_output_for_last_word(full_output: torch.Tensor) -> torch.Tensor:\n",
    "        return full_output[:,-1,:]\n",
    "    \n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        mask_size = input.shape[0]\n",
    "        if self.input_mask is None or self.input_mask.size(0) != mask_size:\n",
    "            self.input_mask = self.__generate_input_mask(mask_size).to(device)\n",
    "            \n",
    "        input = self.embedding(input) * self.embedding_scale\n",
    "        input = self.positional_encoder(input)\n",
    "        output = self.transformer_encoder(input, self.input_mask)\n",
    "        #output = self.__get_output_for_last_word(output)\n",
    "        output = self.decoder(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and batch data\n",
    "-------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training process uses Wikitext-2 dataset from ``torchtext``. The\n",
    "vocab object is built based on the train dataset and is used to numericalize\n",
    "tokens into tensors. Starting from sequential data, the ``batchify()``\n",
    "function arranges the dataset into columns, trimming off any tokens remaining\n",
    "after the data has been divided into batches of size ``batch_size``.\n",
    "For instance, with the alphabet as the sequence (total length of 26)\n",
    "and a batch size of 4, we would divide the alphabet into 4 sequences of\n",
    "length 6:\n",
    "\n",
    "\\begin{align}\\begin{bmatrix}\n",
    "  \\text{A} & \\text{B} & \\text{C} & \\ldots & \\text{X} & \\text{Y} & \\text{Z}\n",
    "  \\end{bmatrix}\n",
    "  \\Rightarrow\n",
    "  \\begin{bmatrix}\n",
    "  \\begin{bmatrix}\\text{A} \\\\ \\text{B} \\\\ \\text{C} \\\\ \\text{D} \\\\ \\text{E} \\\\ \\text{F}\\end{bmatrix} &\n",
    "  \\begin{bmatrix}\\text{G} \\\\ \\text{H} \\\\ \\text{I} \\\\ \\text{J} \\\\ \\text{K} \\\\ \\text{L}\\end{bmatrix} &\n",
    "  \\begin{bmatrix}\\text{M} \\\\ \\text{N} \\\\ \\text{O} \\\\ \\text{P} \\\\ \\text{Q} \\\\ \\text{R}\\end{bmatrix} &\n",
    "  \\begin{bmatrix}\\text{S} \\\\ \\text{T} \\\\ \\text{U} \\\\ \\text{V} \\\\ \\text{W} \\\\ \\text{X}\\end{bmatrix}\n",
    "  \\end{bmatrix}\\end{align}\n",
    "\n",
    "These columns are treated as independent by the model, which means that\n",
    "the dependence of ``G`` and ``F`` can not be learned, but allows more\n",
    "efficient batch processing.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to generate input and target sequence\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``get_batch()`` function generates the input and target sequence for\n",
    "the transformer model. It subdivides the source data into chunks of\n",
    "length ``bptt``. For the language modeling task, the model needs the\n",
    "following words as ``Target``. For example, with a ``bptt`` value of 2,\n",
    "we’d get the following two Variables for ``i`` = 0:\n",
    "\n",
    "![](../_static/img/transformer_input_target.png)\n",
    "\n",
    "\n",
    "It should be noted that the chunks are along dimension 0, consistent\n",
    "with the ``S`` dimension in the Transformer model. The batch dimension\n",
    "``N`` is along dimension 1.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_tensor(text_field: torchtext.data.Field, input_text) -> torch.Tensor:\n",
    "    return text_field.numericalize([input_text.examples[0].text])\n",
    "\n",
    "\n",
    "def load_and_split_data(): \n",
    "    '''\n",
    "    Returns: training_text, validation_text, test_text, vocabulary_object\n",
    "    '''\n",
    "    text_field = torchtext.data.Field(tokenize=get_tokenizer(\"basic_english\"),\n",
    "                                      init_token='<sos>',\n",
    "                                      eos_token='<eos>',\n",
    "                                      lower=True)\n",
    "    train, validation, test = torchtext.datasets.WikiText2.splits(text_field)\n",
    "    text_field.build_vocab(train)\n",
    "    train = text_to_tensor(text_field, train)\n",
    "    validation = text_to_tensor(text_field, validation)\n",
    "    test = text_to_tensor(text_field, test)\n",
    "    return train, validation, test, text_field.vocab\n",
    "                           \n",
    "\n",
    "def divide_into_parallel_data_streams(data: torch.Tensor, stream_count: int) -> torch.Tensor:\n",
    "    stream_length = data.size(0) // stream_count\n",
    "    data = data.narrow(0, 0, stream_length * stream_count)\n",
    "    data = data.view(stream_count, -1).t().contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "\n",
    "def batch_loader(source, max_sequence_length: int) -> (torch.Tensor, torch.Tensor):\n",
    "    total_row_count = source.size(0)\n",
    "    # -1 to account for the target sequence shift\n",
    "    full_batch_count = (total_row_count - 1) // max_sequence_length\n",
    "    for batch_index in range(full_batch_count):\n",
    "        first_row_index = batch_index * max_sequence_length\n",
    "        last_row_index = first_row_index + max_sequence_length\n",
    "        inputs = source[first_row_index: last_row_index]\n",
    "        targets = source[first_row_index+1: last_row_index+1].view(-1)\n",
    "        yield inputs, targets\n",
    "        \n",
    "    first_row_index = full_batch_count * max_sequence_length\n",
    "    inputs = source[first_row_index:-1]\n",
    "    targets = source[first_row_index+1:].view(-1)\n",
    "    yield inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data, vocab = load_and_split_data()\n",
    "\n",
    "batch_size = 20\n",
    "eval_batch_size = 10\n",
    "\n",
    "train_data = divide_into_parallel_data_streams(train_data, batch_size)\n",
    "val_data = divide_into_parallel_data_streams(val_data, eval_batch_size)\n",
    "test_data = divide_into_parallel_data_streams(test_data, eval_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate an instance\n",
    "--------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is set up with the hyperparameter below. The vocab size is\n",
    "equal to the length of the vocab object.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = len(vocab.stoi) # the size of vocabulary\n",
    "emsize = 200 # embedding dimension\n",
    "nhid = 200 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 3 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 4 # the number of heads in the multiheadattention models\n",
    "dropout = 0.2 # the dropout value\n",
    "model = TransformerScriptGenerator(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ntokens = len(TEXT.vocab.stoi) # the size of vocabulary\n",
    "emsize = 200 # embedding dimension\n",
    "nhid = 200 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 3 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 4 # the number of heads in the multiheadattention models\n",
    "dropout = 0.2 # the dropout value\n",
    "model = TransformerScriptGenerator(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)\n",
    "\n",
    "| end of epoch  10 | time: 211.53s | valid loss  5.36 | valid ppl   212.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model\n",
    "-------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CrossEntropyLoss <https://pytorch.org/docs/master/nn.html?highlight=crossentropyloss#torch.nn.CrossEntropyLoss>`__\n",
    "is applied to track the loss and\n",
    "`SGD <https://pytorch.org/docs/master/optim.html?highlight=sgd#torch.optim.SGD>`__\n",
    "implements stochastic gradient descent method as the optimizer. The initial\n",
    "learning rate is set to 5.0. `StepLR <https://pytorch.org/docs/master/optim.html?highlight=steplr#torch.optim.lr_scheduler.StepLR>`__ is\n",
    "applied to adjust the learn rate through epochs. During the\n",
    "training, we use\n",
    "`nn.utils.clip_grad_norm\\_ <https://pytorch.org/docs/master/nn.html?highlight=nn%20utils%20clip_grad_norm#torch.nn.utils.clip_grad_norm_>`__\n",
    "function to scale all the gradient together to prevent exploding.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 5.0 # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "input_sequence_length = 35\n",
    "\n",
    "def evaluate(eval_model, data_source):\n",
    "    eval_model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    ntokens = len(vocab.stoi)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, data_source.size(0) - 1, input_sequence_length):\n",
    "            data, targets = get_batch(data_source, i)\n",
    "            output = eval_model(data)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += len(data) * criterion(output_flat, targets).item()\n",
    "    return total_loss / (len(data_source) - 1)\n",
    "\n",
    "\n",
    "def train2():\n",
    "    \n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    ntokens = len(vocab.stoi)\n",
    "    \n",
    "    for batch_index, (data, targets)  in enumerate(batch_loader(train_data, input_sequence_length)):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output.view(-1, ntokens), targets)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        log_interval = 200\n",
    "        if batch_index % log_interval == 0 and batch_index > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
    "                  'lr {:02.2f} | ms/batch {:5.2f} | '\n",
    "                  'loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "                    epoch, batch_index, len(train_data) // input_sequence_length, scheduler.get_lr()[0],\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over epochs. Save the model if the validation loss is the best\n",
    "we've seen so far. Adjust the learning rate after each epoch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   200/ 2981 batches | lr 5.00 | ms/batch 60.45 | loss  5.84 | ppl   343.92\n",
      "| epoch   1 |   400/ 2981 batches | lr 5.00 | ms/batch 61.64 | loss  5.83 | ppl   339.91\n",
      "| epoch   1 |   600/ 2981 batches | lr 5.00 | ms/batch 60.38 | loss  5.67 | ppl   289.49\n",
      "| epoch   1 |   800/ 2981 batches | lr 5.00 | ms/batch 60.73 | loss  5.68 | ppl   294.18\n",
      "| epoch   1 |  1000/ 2981 batches | lr 5.00 | ms/batch 60.36 | loss  5.62 | ppl   276.54\n",
      "| epoch   1 |  1200/ 2981 batches | lr 5.00 | ms/batch 60.09 | loss  5.64 | ppl   282.77\n",
      "| epoch   1 |  1400/ 2981 batches | lr 5.00 | ms/batch 60.50 | loss  5.65 | ppl   284.96\n",
      "| epoch   1 |  1600/ 2981 batches | lr 5.00 | ms/batch 60.08 | loss  5.69 | ppl   294.70\n",
      "| epoch   1 |  1800/ 2981 batches | lr 5.00 | ms/batch 60.01 | loss  5.62 | ppl   274.56\n",
      "| epoch   1 |  2000/ 2981 batches | lr 5.00 | ms/batch 59.86 | loss  5.64 | ppl   281.20\n",
      "| epoch   1 |  2200/ 2981 batches | lr 5.00 | ms/batch 59.77 | loss  5.53 | ppl   252.67\n",
      "| epoch   1 |  2400/ 2981 batches | lr 5.00 | ms/batch 59.90 | loss  5.60 | ppl   270.71\n",
      "| epoch   1 |  2600/ 2981 batches | lr 5.00 | ms/batch 59.92 | loss  5.61 | ppl   271.93\n",
      "| epoch   1 |  2800/ 2981 batches | lr 5.00 | ms/batch 60.01 | loss  5.54 | ppl   255.65\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-074d9e0aba62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mepoch_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtrain2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m89\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
      "\u001b[1;32m<ipython-input-12-aaf9d3fbdf0f>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(eval_model, data_source)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_source\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_sequence_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0moutput_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_batch' is not defined"
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "epochs = 1 # The number of epochs\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train2()\n",
    "    val_loss = evaluate(model, val_data)\n",
    "    print('-' * 89)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
    "          'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                     val_loss, math.exp(val_loss)))\n",
    "    print('-' * 89)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model with the test dataset\n",
    "-------------------------------------\n",
    "\n",
    "Apply the best model to check the result with the test dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = evaluate(best_model, test_data)\n",
    "print('=' * 89)\n",
    "print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n",
    "    test_loss, math.exp(test_loss)))\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.eval();\n",
    "vocab_size = len(TEXT.vocab.stoi)\n",
    "print(vocab_size)\n",
    "data, targets = get_batch(train_data, 0)\n",
    "print(f\"BPTT = {bptt}\")\n",
    "print(f\"Input shape = {data.shape}\")\n",
    "print(f\"Target shape = {targets.shape}\")\n",
    "output = best_model(data)\n",
    "print(f\"Output shape = {output.shape}\")\n",
    "output_flat = output.view(-1, ntokens)\n",
    "print(f\"Output flat shape = {output_flat.shape}\")\n",
    "output_flat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_list(tensor: torch.Tensor) -> list:\n",
    "    return tensor.cpu().detach().numpy().tolist()\n",
    "\n",
    "\n",
    "def scores_to_top_tokens(scores: torch.Tensor) -> list:\n",
    "    _, top_index_tensor = torch.topk(scores, k=1)\n",
    "    top_index_tensor.squeeze_().t_()\n",
    "    top_index_list = tensor_to_list(top_index_tensor)\n",
    "    return top_index_list\n",
    "\n",
    "\n",
    "def tokens_to_words(batches: list) -> list:\n",
    "    decoded_batches = []\n",
    "    for batch in batches:\n",
    "        decoded_batch = [TEXT.vocab.itos[token] for token in batch]\n",
    "        decoded_batches.append(decoded_batch)\n",
    "    return decoded_batches\n",
    "\n",
    "\n",
    "def decode_transformer_output(scores: torch.Tensor) -> list:\n",
    "    top_tokens = scores_to_top_tokens(scores)\n",
    "    predicted_words = tokens_to_words(top_tokens)\n",
    "    return predicted_words\n",
    "\n",
    "\n",
    "def decode_targets(targets: torch.Tensor, batch_size: int) -> list:\n",
    "    unsquashed_targets = targets.view(-1, batch_size).t()\n",
    "    target_tokens = tensor_to_list(unsquashed_targets)\n",
    "    return tokens_to_words(target_tokens)\n",
    "\n",
    "\n",
    "def decode_inputs(inputs: torch.Tensor) -> list:\n",
    "    input_tokens = tensor_to_list(inputs.t())\n",
    "    return tokens_to_words(input_tokens)\n",
    "\n",
    "\n",
    "def join_sequences(decoded_sequences: list) -> list:\n",
    "    return [\" \".join(sequence) for sequence in decoded_sequences]\n",
    "\n",
    "\n",
    "def present_result(model, inputs: torch.Tensor, targets: torch.Tensor, index: int) -> None:\n",
    "    model.eval()\n",
    "    output = model(inputs)\n",
    "    input_text = join_sequences(decode_inputs(inputs))[index]\n",
    "    target_text = join_sequences(decode_targets(targets, 20))[index]\n",
    "    output_text = join_sequences(decode_transformer_output(output))[index]\n",
    "    print( \"INPUT\\n-----\\n\" \n",
    "          f\"{input_text}\\n\\n\"\n",
    "           \"TARGET\\n------\\n\"\n",
    "          f\"{target_text}\\n\\n\"\n",
    "           \"OUTPUT\\n------\\n\"\n",
    "          f\"{output_text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "present_result(best_model, data, targets, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(text: str) -> str:\n",
    "    encoded_text = TEXT.numericalize([text.split()]).to(device)\n",
    "    custom_out = best_model(encoded_text)\n",
    "    custom_out.shape\n",
    "    _, custom_top_tokens = torch.topk(custom_out, k=1)\n",
    "    out_tokens = tensor_to_list(custom_top_tokens.squeeze())\n",
    "    return [TEXT.vocab.itos[token] for token in out_tokens][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"that the primary schools , and the kakapo \"\n",
    "for i in range(30):\n",
    "    input = \" \".join(sentence.split()[-20:])\n",
    "    print(input)\n",
    "    sentence += predict_next_word(input) + \" \"\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(eval_model, data_source):\n",
    "    eval_model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    ntokens = len(TEXT.vocab.stoi)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, data_source.size(0) - 1, input_sequence_length):\n",
    "            data, targets = get_batch(data_source, i)\n",
    "            output = eval_model(data)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += len(data) * criterion(output_flat, targets).item()\n",
    "    return total_loss / (len(data_source) - 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
